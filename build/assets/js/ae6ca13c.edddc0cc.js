"use strict";(self.webpackChunkdatafuse=self.webpackChunkdatafuse||[]).push([[4930],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=d(n),m=r,f=u["".concat(s,".").concat(m)]||u[m]||c[m]||i;return n?a.createElement(f,o(o({ref:t},p),{},{components:n})):a.createElement(f,o({ref:t},p))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var d=2;d<i;d++)o[d]=n[d];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},7005:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return d},toc:function(){return p},default:function(){return u}});var a=n(7462),r=n(3366),i=(n(7294),n(3905)),o=["components"],l={id:"datafuse-store-design",title:"DatafuseStore Design",sidebar_position:4},s=void 0,d={unversionedId:"development/rfcs/datafuse-store-design",id:"development/rfcs/datafuse-store-design",isDocsHomePage:!1,title:"DatafuseStore Design",description:"DatafuseStore is the storage layer in charge of:",source:"@site/docs/development/rfcs/0001-store-design.md",sourceDirName:"development/rfcs",slug:"/development/rfcs/datafuse-store-design",permalink:"/docs/development/rfcs/datafuse-store-design",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/development/rfcs/0001-store-design.md",version:"current",sidebarPosition:4,frontMatter:{id:"datafuse-store-design",title:"DatafuseStore Design",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"DatafuseQuery Shuffle",permalink:"/docs/development/rfcs/DatafuseQuery-Shuffle"},next:{title:"Performance Test",permalink:"/docs/development/rfcs/Performance-Test"}},p=[{value:"Meta data cluster",id:"meta-data-cluster",children:[]},{value:"In-process metadata components",id:"in-process-metadata-components",children:[]},{value:"Meta data structure",id:"meta-data-structure",children:[]},{value:"File format",id:"file-format",children:[]},{value:"Data placement",id:"data-placement",children:[]},{value:"Replication",id:"replication",children:[]},{value:"Meta cluster startup",id:"meta-cluster-startup",children:[]}],c={toc:p};function u(e){var t=e.components,n=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"DatafuseStore is the storage layer in charge of:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"meta data storage such as user, db, table and schema."),(0,i.kt)("li",{parentName:"ul"},"blocks life cycle management such as allocation, compaction etc."),(0,i.kt)("li",{parentName:"ul"},"data/metadata consistency and reliability.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"                  DatafuseQuery(client)\n                      |\n                      | rpc\n                      v\n  DatafuseStore       | flightServer                // network, auth\n                |     |\n                |     v\n                |  Handler                    // execution engine\n                |     |\n                |     v\n                | IFileSystem                 // abstract storage layer\n")),(0,i.kt)("h1",{id:"ifilesystem"},"IFileSystem"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," defines an abstract storage layer that DatafuseStore would runs on.\nAn ",(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," impl in the cluster is the only stateful component."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Local FS: impl ",(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," API and use a local disk folder as storage.\nSuitable for a single node DatafuseQuery deployment.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"DFS: impl ",(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," and setup an aws-S3 like storage service.\nA DFS organizes multiple ",(0,i.kt)("inlineCode",{parentName:"p"},"LocalFS")," with a centralized meta data service.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Object Storage Adapters: an ",(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," impl that builds upon an object\nstorage service on cloud."))),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," defines following API-s:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"add"),": AKA put-if-absent: add a file only if it is absent."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"read_all"),": read all bytes of a file."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"list"),": retrieve a list of files with specified prefix."),(0,i.kt)("li",{parentName:"ul"},"TODO")),(0,i.kt)("h1",{id:"api"},"API"),(0,i.kt)("p",null,"DatafuseQuery and DatafuseStore talks arrow-flight protocol."),(0,i.kt)("p",null,"Schema related operations such as ",(0,i.kt)("inlineCode",{parentName:"p"},"create table")," or ",(0,i.kt)("inlineCode",{parentName:"p"},"create database")," are wrapped with a ",(0,i.kt)("inlineCode",{parentName:"p"},"FlightService::do_action")," RPC.\nData operation such as reading or writing a block are done with\n",(0,i.kt)("inlineCode",{parentName:"p"},"FlightService::do_get")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"FlightService::do_put"),"."),(0,i.kt)("p",null,"See ",(0,i.kt)("inlineCode",{parentName:"p"},"common/flights/src/store_client.rs"),"."),(0,i.kt)("h1",{id:"dfs"},"DFS"),(0,i.kt)("p",null,"The most important component in DatafuseStore is the DFS.\nDFS mainly consists of two parts: the meta data cluster and block storage\ncluster."),(0,i.kt)("p",null,"Block cluster is unaware of data placement and is purely a set of servers\nproviding object like write and read API."),(0,i.kt)("p",null,"Data placement is part of the meta data and is stored in the meta cluster."),(0,i.kt)("h2",{id:"meta-data-cluster"},"Meta data cluster"),(0,i.kt)("p",null,"All meta(the cluster meta and file keys) has a copy that resides in memory on every node for instant access."),(0,i.kt)("p",null,"Every update to meta is done by committing a raft log of the updated entry into meta cluster."),(0,i.kt)("p",null,"A cluster keeps its meta data in a raft group with typically 5 candidate nodes\nand all other nodes as learners.\nCandidate nodes provides meta data read and write API.\nEvery other node is a ",(0,i.kt)("strong",{parentName:"p"},"learner"),", which does not elect but just subscribes\nmeta change message from the 5 candidates."),(0,i.kt)("h2",{id:"in-process-metadata-components"},"In-process metadata components"),(0,i.kt)("p",null,"A DatafuseStore process includes two grpc API: the flight service and the meta\nservice."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Meta related components are wrapped into ",(0,i.kt)("inlineCode",{parentName:"p"},"MetaNode"),", in which a ",(0,i.kt)("inlineCode",{parentName:"p"},"Raft")," instance\nis maintained along with storage and network engines."),(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"MetaNode")," is the only entry for other DatafuseStore components to access meta data.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"RaftNode")," communicates with remote RaftNode through ",(0,i.kt)("inlineCode",{parentName:"p"},"Network"),", which send\nmessages to meta-grpc service on other DatafuseStore nodes.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"Network")," relies on ",(0,i.kt)("inlineCode",{parentName:"p"},"Storage")," to find out info of other nodes."))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"DatafuseStore components:\n.---------------------------.\n|                           |\n| flight-grpc     meta-grpc |\n|     |               |     |\n|     '--.      .-----'     |\n|        v      v           |\n|        MetaNode           |\n|        |     |            |\n|        |     v            |\n|        |    RaftNode      |\n|        |  .--'   |        |\n|        v  v      v        |\n|      Storage <- Network   |\n|                           |\n'---------------------------'\n")),(0,i.kt)("h2",{id:"meta-data-structure"},"Meta data structure"),(0,i.kt)("p",null,"Meta data includes hardware information: nodes, the file information: keys and\ndata placement information: slots."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-proto"},"message Meta {\n    map<string, string> keys;\n    repeated Slot slots;\n    map<int64, Node> nodes\n}\n\nmessage Node {\n    int64 NodeId\n    repeated string Addresses\n}\n\nmessage Slot {\n    repeated int64 node_ids;\n}\n")),(0,i.kt)("h2",{id:"file-format"},"File format"),(0,i.kt)("p",null,"A data block in DFS or local-FS is a complete Parquet data, with schema embedded.\nThe schema in block should always be identical to the schema stored in\ntable-meta. Otherwise it is a severe bug."),(0,i.kt)("p",null,"Parquet has its own segmentation and index in it which is similar to ClickHouse\nfile structure."),(0,i.kt)("p",null,"See: ",(0,i.kt)("a",{parentName:"p",href:"https://parquet.apache.org/documentation/latest/"},"https://parquet.apache.org/documentation/latest/")),(0,i.kt)("p",null,"A schema file such as table or database is in protobuf format."),(0,i.kt)("h2",{id:"data-placement"},"Data placement"),(0,i.kt)("p",null,"A file in DFS has 3 copies.\nA file is identified with a unique ",(0,i.kt)("inlineCode",{parentName:"p"},"key"),".\nEvery ",(0,i.kt)("inlineCode",{parentName:"p"},"key")," is assigned to a virtual allocation unit ",(0,i.kt)("inlineCode",{parentName:"p"},"slot")," by some hash algo.\nA ",(0,i.kt)("inlineCode",{parentName:"p"},"slot")," is assigned to 3 nodes. The slot-to-nodes mapping is part of the DFS meta data."),(0,i.kt)("h2",{id:"replication"},"Replication"),(0,i.kt)("p",null,"Once a data block is persisted on local fs and the corresponding meta data is\ncommitted, DFS ack the client an OK message."),(0,i.kt)("p",null,"Every node is either a follower or leaner of the meta data raft group thus will\nreceive the meta changes.\nIf a node found that a ",(0,i.kt)("inlineCode",{parentName:"p"},"key")," is uploaded and the ",(0,i.kt)("inlineCode",{parentName:"p"},"slot")," for the ",(0,i.kt)("inlineCode",{parentName:"p"},"key")," is on this\nnode, it pulls the data block from the uploading node."),(0,i.kt)("h2",{id:"meta-cluster-startup"},"Meta cluster startup"),(0,i.kt)("p",null,"A DatafuseStore cluster is stateful thus the startup is done in several steps:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Boot up the first node in a cluster, by calling ",(0,i.kt)("inlineCode",{parentName:"p"},"MetaNode::boot()"),".\nThis func creates an empty raft instance add initialize itself as the leader of the solo cluster.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Creating node is done with ",(0,i.kt)("inlineCode",{parentName:"p"},"MetaNode::boot_non_voter()"),".\nThis func does nothing more than initializing a raft instance.\nIt returns the ",(0,i.kt)("inlineCode",{parentName:"p"},"MetaNode")," instance with network API ready for accepting raft communications.\nAt this point it is unaware of anything about the cluster."),(0,i.kt)("p",{parentName:"li"},"To add this new node to a cluster, send an ",(0,i.kt)("inlineCode",{parentName:"p"},"Cmd::AddNode")," request to the leader.\nThe leader will then commit the node info into its own storage and start sending\nraft snapshot and logs to the new node."))),(0,i.kt)("p",null,"When a node is shutting down and restarted, just the ",(0,i.kt)("inlineCode",{parentName:"p"},"MetaNode::new()")," is used to start the meta-service.\nWhen a node is restarted:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"A candidate(AKA voter) that becomes the new leader is able to find out every node from its local storage and then add them as non-voter in order to replicate logs to them."),(0,i.kt)("li",{parentName:"ul"},"A non-voter has nothing to do other than receiving logs from the leader.")),(0,i.kt)("h1",{id:"dfs-example"},"DFS Example"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"FQ:      DatafuseQuery node\n\nflight:  arrow-flight server\nhandler: execution handler\nDFS:     distributed FS\nFS:      local FS\n\nL:       leader of raft for meta\nF:       follower of raft\nlnr:     learner\n\n                 FQ\n                 |\n                 | 1. put block\n                 |    or create table\n                 |\n-----------------|-------------------------------------\n                 v\n                 flight <-----.  flight\n                 |            |\n                 | 2.         | 8. pull block\n    5. commit    |            |\n       meta      v            |\n         .-------handler      '- handler\n         |       |               |  ^\n         |       | 3.         9. |  |\n         |       v               v  |\n         |       DFS             DFS|\n         |       |               |  |\n         |       | 4.        10. |  |\n         |       v               v  |\n         |       FS              FS | 7. notify handler\n         |                          |    of meta changes\n         v      6. meta bcast       |\nmeta   : L----+-------+------+------|-+-------.\n              `->F    `->F    `->F  | `->F    `->lnr\n                                  `-'\nnodes:   N1      N2      N3      N4      N5      N6 ...\n")),(0,i.kt)("h1",{id:"table-format"},"Table format"),(0,i.kt)("p",null,"A table in ",(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," consists of several files and the structure is similar\nto a append-only log:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Table head: contains schema and a pointer to the latest manifest file.\nThe table head must be updated ",(0,i.kt)("strong",{parentName:"p"},"atomically"),".")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Manifest: describes what data blocks belongs to a table.\nThere is a list of data block files pointing to the latest updates,\nand a pointer to previous manifest i.e., the last version this update based\non.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Data: a collection of operation logs."))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"T: table head\nMi: manifest\ndi: data block files\n\n                   T\n                   |\n                   v\nM0 <---- M1 <----- M2\n|        |         |\n`-> d0   +-> d1    +-> d3\n         |         |\n         `-> d2    `-> d4\n\n")),(0,i.kt)("p",null,"A typical update workflow would be like the following:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("ol",{parentName:"li"},(0,i.kt)("li",{parentName:"ol"},"Handler receives a batch of updates, including inserts and deletes.\nIt writes to one or more data blocks, with some unique keys."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("ol",{parentName:"li",start:2},(0,i.kt)("li",{parentName:"ol"},"Handler reads the latest table head file, finds out the latest manifest,\ne.g., M1, and compose a new manifest e.g., M2, containing the data block\nkeys from step-1 and a pointer to M1.\nWrite it to DFS with a unique key."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("ol",{parentName:"li",start:3},(0,i.kt)("li",{parentName:"ol"},"Handler atomically update the table head file to change the latest manifest\npointer to M2. If race encountered, retry from step-2.")))),(0,i.kt)("p",null,"The challenge is on step-3:"),(0,i.kt)("p",null,"An ",(0,i.kt)("inlineCode",{parentName:"p"},"IFileSystem")," impl may not support atomic update.\nIn this case, write the table head file with a mono-incremental key, e.g.\n",(0,i.kt)("inlineCode",{parentName:"p"},"t-001"),", then ",(0,i.kt)("inlineCode",{parentName:"p"},"t-002")," ...\nAnd a read operation should list all of the heads and find out the latest version(resulting in eventual consistency).\nThis strategy only requires atomic-add operation, i.e., put-if-absent."),(0,i.kt)("p",null,"Atomic-add can be done on behalf of the meta cluster, since it is an easy job\nfor a raft group or any other consensus group to generate mono-incremental ids."),(0,i.kt)("h1",{id:"table-compaction"},"Table compaction"),(0,i.kt)("p",null,"Compaction merges several earliest manifest into one, and optionally merges\noverlapping data blocks."),(0,i.kt)("p",null,"Compaction generates a new manifest e.g., M1' from M1. Then it removes M0 and M1."),(0,i.kt)("p",null,"A reading process should try to read both M1 and M1', and use either one it\nsees."),(0,i.kt)("p",null,"A manifest or data block will be added or removed, but never updated,\n",(0,i.kt)("strong",{parentName:"p"},"since in a distributed system updating data results in super complicated consistency\nchallenges"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"                   T\n                   |\n                   v\nM0 <---- M1 <----+ M2\n|        |       | |\n`-> d0   +-> d1  | +-> d3\n         |       | |\n         `-> d2  | `-> d4\n                 |\n                 |\n                 |\n                 |\n         M1' <---'\n         +-> d0\n         |\n         +-> d1\n         |\n         `-> d2\n\n")))}u.isMDXComponent=!0}}]);